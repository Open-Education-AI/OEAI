{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%run oeai_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create an instance of OEAI class and set the platform (\"Synapse\" or \"Fabric\")\n",
        "oeai = OEAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# CHANGE VALUES FOR YOUR KEY VAULT\n",
        "keyvault = \"INSERT_YOUR_KEYVAULT_NAME_HERE\"\"  \n",
        "keyvault_linked_service = \"INSERT_YOUR_KEYVAULT_LINKED_SERVICE_NAME_HERE\"  \n",
        "\n",
        "# Synapse OEA environment paths\n",
        "silver_path = oeai.get_secret(spark, \"wonde-silver\", keyvault_linked_service, keyvault)\n",
        "gold_path = oeai.get_secret(spark, \"gold-path\", keyvault_linked_service, keyvault)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def create_attendance_report(spark, silver_path, gold_path):\n",
        "    \"\"\"\n",
        "    Generates an aggregated attendance report from Delta Lake tables.\n",
        "\n",
        "    This function reads organization, student, and attendance summary data from Delta tables,\n",
        "    performs filtering and joins, and then aggregates the data at both the school and trust levels.\n",
        "    The final aggregated data is written to a Parquet file.\n",
        "\n",
        "    Args:\n",
        "        spark (SparkSession): Active Spark session.\n",
        "        silver_path (str): Path to the silver layer where source Delta tables are stored.\n",
        "        gold_path (str): Path to the gold layer where the aggregated report will be saved.\n",
        "\n",
        "    The function reads 'dim_Organisation', 'dim_Student', and 'fact_AttendanceSummary' tables,\n",
        "    aggregates attendance data, and saves the output as 'agg_attendance.parquet'.\n",
        "    \"\"\"\n",
        "    # Read delta tables\n",
        "    dim_Organisation = spark.read.format(\"delta\").load(silver_path + \"dim_Organisation\")\n",
        "    dim_Student = spark.read.format(\"delta\").load(silver_path + \"dim_Student\")\n",
        "    fact_AttendanceSummary = spark.read.format(\"delta\").load(silver_path + \"fact_AttendanceSummary\")\n",
        "\n",
        "    # Alias the DataFrames\n",
        "    dim_Student = dim_Student.alias(\"student\")\n",
        "    dim_Organisation = dim_Organisation.alias(\"org\")\n",
        "    fact_AttendanceSummary = fact_AttendanceSummary.alias(\"attendance\")\n",
        "\n",
        "    # Filter and join\n",
        "    dim_Student = dim_Student.filter(col(\"Current_Year\").isin([7, 8, 9, 10, 11]))\n",
        "    joined_df = dim_Student.join(dim_Organisation, col(\"student.organisationkey\") == col(\"org.organisationkey\")) \\\n",
        "                           .join(fact_AttendanceSummary, col(\"student.studentkey\") == col(\"attendance.studentkey\"))\n",
        "\n",
        "    # Aggregations\n",
        "    school_agg_df = joined_df.groupBy(\"org.organisationkey\", \"org.Organisation_Name\") \\\n",
        "                             .agg(\n",
        "                                 avg(\"attendance.Percentage_Attendance\").alias(\"avg_percentage_attendance\"),\n",
        "                                 (sum(\"attendance.Is_Persistently_Absent\") / count(\"student.studentkey\")).alias(\"rate_persistent_absence\"),\n",
        "                                 (sum(\"attendance.Is_Severely_Absent\") / count(\"student.studentkey\")).alias(\"rate_severe_absence\")\n",
        "                             )\n",
        "\n",
        "    trust_agg_df = joined_df.agg(\n",
        "        avg(\"attendance.Percentage_Attendance\").alias(\"avg_percentage_attendance\"),\n",
        "        (sum(\"attendance.Is_Persistently_Absent\") / count(\"student.studentkey\")).alias(\"rate_persistent_absence\"),\n",
        "        (sum(\"attendance.Is_Severely_Absent\") / count(\"student.studentkey\")).alias(\"rate_severe_absence\")\n",
        "    ).withColumn(\"organisationkey\", lit(\"Trust\")) \\\n",
        "     .withColumn(\"Organisation_Name\", lit(\"All Schools\"))\n",
        "\n",
        "    # Union and write to Parquet\n",
        "    final_df = trust_agg_df.unionByName(school_agg_df)\n",
        "    final_df.write.mode(\"overwrite\").format(\"parquet\").save(gold_path + \"/agg_attendance.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def create_attendance_report_by_year(spark, silver_path, gold_path):\n",
        "    \"\"\"\n",
        "    Generates an aggregated attendance report by year from Delta Lake tables.\n",
        "\n",
        "    This function reads organization, student, and attendance summary data from Delta tables,\n",
        "    performs joins and aggregates the data by school and overall trust level for each year.\n",
        "    The final aggregated data is written to a Parquet file.\n",
        "\n",
        "    Args:\n",
        "        spark (SparkSession): Active Spark session.\n",
        "        silver_path (str): Path to the silver layer where source Delta tables are stored.\n",
        "        gold_path (str): Path to the gold layer where the aggregated report will be saved.\n",
        "\n",
        "    The function reads 'dim_Organisation', 'dim_Student', and 'fact_AttendanceSummary' tables,\n",
        "    aggregates attendance data by year, and saves the output as 'agg_attendance_by_year.parquet'.\n",
        "    \"\"\"\n",
        "    # Read delta tables\n",
        "    dim_Organisation = spark.read.format(\"delta\").load(silver_path + \"dim_Organisation\")\n",
        "    dim_Student = spark.read.format(\"delta\").load(silver_path + \"dim_Student\")\n",
        "    fact_AttendanceSummary = spark.read.format(\"delta\").load(silver_path + \"fact_AttendanceSummary\")\n",
        "\n",
        "    # Alias and process DataFrames\n",
        "    dim_Student = dim_Student.alias(\"student\").withColumn(\"Current_Year\", col(\"Current_Year\").cast(\"integer\"))\n",
        "    dim_Organisation = dim_Organisation.alias(\"org\")\n",
        "    fact_AttendanceSummary = fact_AttendanceSummary.alias(\"attendance\")\n",
        "\n",
        "    # Filter and join\n",
        "    dim_Student = dim_Student.filter(col(\"Current_Year\").isin([7, 8, 9, 10, 11, 12, 13]))\n",
        "    joined_df = dim_Student.join(dim_Organisation, col(\"student.organisationkey\") == col(\"org.organisationkey\")) \\\n",
        "                           .join(fact_AttendanceSummary, col(\"student.studentkey\") == col(\"attendance.studentkey\"))\n",
        "\n",
        "    # Aggregations\n",
        "    school_year_agg_df = joined_df.groupBy(\"org.organisationkey\", \"org.Organisation_Name\", \"Current_Year\") \\\n",
        "                                  .agg(avg(\"attendance.Percentage_Attendance\").alias(\"avg_percentage_attendance\"))\n",
        "\n",
        "    trust_year_agg_df = joined_df.groupBy(\"Current_Year\") \\\n",
        "                                 .agg(avg(\"attendance.Percentage_Attendance\").alias(\"avg_percentage_attendance\")) \\\n",
        "                                 .withColumn(\"organisationkey\", lit(\"Trust\")) \\\n",
        "                                 .withColumn(\"Organisation_Name\", lit(\"All Schools\"))\n",
        "\n",
        "    # Union and write to Parquet\n",
        "    final_year_df = trust_year_agg_df.unionByName(school_year_agg_df)\n",
        "    final_year_df.write.mode(\"overwrite\").format(\"parquet\").save(gold_path + \"/agg_attendance_by_year.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def create_attendance_report_by_gender(spark, silver_path, gold_path):\n",
        "    \"\"\"\n",
        "    Generates an aggregated attendance report by gender from Delta Lake tables.\n",
        "\n",
        "    This function reads organization, student, and attendance summary data from Delta tables,\n",
        "    performs joins and aggregates the data by gender at both the school and trust levels.\n",
        "    The final aggregated data is written to a Parquet file.\n",
        "\n",
        "    Args:\n",
        "        spark (SparkSession): Active Spark session.\n",
        "        silver_path (str): Path to the silver layer where source Delta tables are stored.\n",
        "        gold_path (str): Path to the gold layer where the aggregated report will be saved.\n",
        "\n",
        "    The function reads 'dim_Organisation', 'dim_Student', and 'fact_AttendanceSummary' tables,\n",
        "    aggregates attendance data by gender, and saves the output as 'agg_attendance_by_gender.parquet'.\n",
        "    \"\"\"\n",
        "    # Read delta tables\n",
        "    dim_Organisation = spark.read.format(\"delta\").load(silver_path + \"dim_Organisation\")\n",
        "    dim_Student = spark.read.format(\"delta\").load(silver_path + \"dim_Student\")\n",
        "    fact_AttendanceSummary = spark.read.format(\"delta\").load(silver_path + \"fact_AttendanceSummary\")\n",
        "\n",
        "    # Alias and process DataFrames\n",
        "    dim_Student = dim_Student.alias(\"student\").filter(col(\"Current_Year\").isin([7, 8, 9, 10, 11]))\n",
        "    dim_Organisation = dim_Organisation.alias(\"org\")\n",
        "    fact_AttendanceSummary = fact_AttendanceSummary.alias(\"attendance\")\n",
        "\n",
        "    # Join and select necessary columns\n",
        "    joined_df = dim_Student.join(dim_Organisation, col(\"student.organisationkey\") == col(\"org.organisationkey\")) \\\n",
        "                           .join(fact_AttendanceSummary, col(\"student.studentkey\") == col(\"attendance.studentkey\")) \\\n",
        "                           .select(\"student.Gender\", \"student.studentkey\", \"org.organisationkey\", \n",
        "                                   \"org.Organisation_Name\", \"attendance.Percentage_Attendance\", \n",
        "                                   \"attendance.Is_Persistently_Absent\", \"attendance.Is_Severely_Absent\")\n",
        "\n",
        "    # Aggregations\n",
        "    school_agg_df = joined_df.groupBy(\"org.organisationkey\", \"org.Organisation_Name\") \\\n",
        "                             .pivot(\"student.Gender\") \\\n",
        "                             .agg(\n",
        "                                 avg(\"attendance.Percentage_Attendance\").alias(\"avg_percentage_attendance\"),\n",
        "                                 (sum(\"attendance.Is_Persistently_Absent\") / count(\"student.studentkey\")).alias(\"rate_persistent_absence\"),\n",
        "                                 (sum(\"attendance.Is_Severely_Absent\") / count(\"student.studentkey\")).alias(\"rate_severe_absence\")\n",
        "                             )\n",
        "\n",
        "    trust_agg_df = joined_df.groupBy().pivot(\"student.Gender\").agg(\n",
        "        avg(\"attendance.Percentage_Attendance\").alias(\"avg_percentage_attendance\"),\n",
        "        (sum(\"attendance.Is_Persistently_Absent\") / count(\"student.studentkey\")).alias(\"rate_persistent_absence\"),\n",
        "        (sum(\"attendance.Is_Severely_Absent\") / count(\"student.studentkey\")).alias(\"rate_severe_absence\")\n",
        "    ).withColumn(\"organisationkey\", lit(\"Trust\")) \\\n",
        "     .withColumn(\"Organisation_Name\", lit(\"All Schools\"))\n",
        "\n",
        "    # Union and write to Parquet\n",
        "    final_df = trust_agg_df.unionByName(school_agg_df)\n",
        "    final_df.write.mode(\"overwrite\").format(\"parquet\").save(gold_path + \"/agg_attendance_by_gender.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create the aggregation tables\n",
        "create_attendance_report(spark, silver_path, gold_path)\n",
        "create_attendance_report_by_year(spark, silver_path, gold_path)\n",
        "create_attendance_report_by_gender(spark, silver_path, gold_path)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
