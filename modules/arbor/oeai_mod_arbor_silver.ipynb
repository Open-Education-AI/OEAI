{"cells":[{"cell_type":"code","execution_count":null,"id":"0968c9e9-1d74-476a-b188-3795a7e5ea83","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["%run oeai_py"]},{"cell_type":"code","execution_count":null,"id":"9a8a63ee-3b6d-478f-967c-cfc0008a44e8","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["oeai = OEAI(platform=\"Fabric\")"]},{"cell_type":"code","execution_count":null,"id":"fec6dfbe-4fe4-406a-bf26-f89f89bd3a7a","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# CHANGE VALUES FOR YOUR KEY VAULT\n","keyvault = \"INSERT KEY VAULT NAME HERE\"\"  \n","keyvault_linked_service = \"\"  \n","\n","# Synapse OEA environment paths\n","bronze_path = oeai.get_secret(spark, \"arbor-Bronze\", keyvault_linked_service, keyvault)\n","silver_path = oeai.get_secret(spark, \"arbor-Silver\", keyvault_linked_service, keyvault)\n","#gold_path = oeai.get_secret(spark, \"gold-path\", keyvault_linked_service, keyvault)\n","#school_ids_secret = oeai.get_secret(spark, \"arbor-ids\", keyvault_linked_service, keyvault)\n","#subdirectories = school_ids_secret.split(\",\")"]},{"cell_type":"code","execution_count":null,"id":"be3da5b0-1b3b-4eb6-9e8e-07b98591d95b","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Define the mapping between JSON files and desired Delta table names\n","delta_table_name_mapping = {\n","    \"schools.csv\": \"dim_Organisation\",\n","    \"students.csv\": \"dim_Student\",\n","    \"students_extended.csv\": \"dim_StudentExtended\",\n","    \"attendancesession.csv\": \"fact_AttendanceSession\",\n","   \n","}"]},{"cell_type":"code","execution_count":null,"id":"960ed63f-5f78-4635-b548-d89aff096de7","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["column_mappings = {\n","    \"schools.csv\": {\n","        # drops\n","        \"ABBREVIATED_NAME\": \"drop\",\n","        #\"school_id\": \"drop\",\n","        # Renames\n","        \"APPLICATION_ID\": {\"new_name\": \"school_id\"}, \n","        \"NAME\": {\"new_name\": \"Organisation_Name\"},    \n","        \"PHASE\": {\"new_name\": \"Organisation_Type\"},\n","        # adds\n","        \"add_columns\": {\n","            \"organisationkey\": \"\",  \n","            \"addresskey\": \"\",  \n","            \"UKPRN\": \"\",\n","            \"Organisation_Status\": \"Active\",\n","            \"last_updated\": \"\",\n","            \"Establishment_Number\": \"\",\n","            \"URN\": \"\",\n","            \"LA_Code\": \"\",\n","            \"unique_key\": \"\",\n","        }\n","    },\n","    \"students.csv\": {\n","        # drops   \n","        \"STUDENT_UNIQUE_ID\": \"drop\",\n","        #\"UPN\": \"drop\",\n","        \"IS_CURRENT\": \"drop\",\n","        \"SEX\": \"drop\",\n","        \"ETHNICITY\": \"drop\",\n","        \"RELIGION\": \"drop\",\n","        \"NATIVE_LANGUAGE_CODES\": \"drop\",\n","        \"NATIVE_LANGUAGE_NAMES\": \"drop\",\n","        \"EMAIL_ADDRESS\": \"drop\",\n","        \"NATINALITIES\": \"drop\",\n","        \"CURRENT_YEAR_GROUP\": \"drop\",\n","        \"CURRENT_SEN_STATUS\": \"drop\",\n","        \"CURRENT_REGISTRATION_GROUP\": \"drop\",\n","        \"CHILD_PROTECTION\": \"drop\",\n","        \"GIFTED\": \"drop\",\n","        \"GIFTED_TALENTED\": \"drop\",\n","        \"HAS_MEDICAL_CONDITION\": \"drop\",\n","        \"IN_CARE\": \"drop\",\n","        \"IN_YEAR_ADMISSION\": \"drop\",\n","        \"OUT_OF_AGE_GROUP_COHORT\": \"drop\",\n","        \"SEN\": \"drop\",\n","        \"TALENTED\": \"drop\",\n","        \"EAL\": \"drop\",\n","        \"COMPULSORY_SCHOOL_AGE\": \"drop\",\n","        \"EVER_6-FSM\": \"drop\",\n","        \"EARLY_YEARS_PUPIL_PREMIUM_RECIPIENT\": \"drop\",\n","        \"EVER_6SERVICE_CHILD\": \"drop\",\n","        \"FSM\": \"drop\",\n","        \"MOBILE_Y10_Y11\": \"drop\",\n","        \"MOBILE_Y5_Y6\": \"drop\",\n","        \"PUPIL_PREMIUM\": \"drop\",\n","        \"PUPIL_PREMIUM_RECIPIENT\": \"drop\",\n","        \"SERVICE_CHILD\": \"drop\",\n","        \"TRAVELLER\": \"drop\",\n","        \"DISADVANTAGED\": \"drop\",\n","        # Renames\n","        \"UPN\": {\"new_name\": \"UPN\"}, \n","        \"DATE_OF_BIRTH\": {\"new_name\": \"Date_Of_Birth\"}, \n","        \"LEGAL_FIRST_NAME\": {\"new_name\": \"Forename\"}, \n","        \"GENDER\": {\"new_name\": \"Gender\"}, \n","        \"STUDENT_ID\": {\"new_name\": \"student_id\"}, \n","        \"LEGAL_FIRST_NAME\": {\"new_name\": \"Legal_Forename\"}, \n","        \"LEGAL_LAST_NAME\": {\"new_name\": \"Legal_Surname\"}, \n","        \"PREFERRED_LAST_NAME\": {\"new_name\": \"Surname\"},\n","        \"PREFERRED_FIRST_NAME\": {\"new_name\": \"Forename\"},       \n","        \"APPLICATION_ID\": {\"new_name\": \"school_id\"},\n","        # adds\n","        \"add_columns\": {\n","            \"organisationkey\": \"\",\n","            \"studentkey\": \"\",\n","            \"Middle_Names\":\"\",\n","            \"addresskey\":\"\",\n","            \"ULN\":\"\",\n","            \"last_updated\":\"\",\n","            \"unique_key\": \"\",\n","        }\n","    },\n","    \"students_extended.csv\": {\n","        # drops\n","        \n","        \"STUDENT_UNIQUE_ID\": \"drop\",\n","        \n","        \"UPN\": \"drop\",\n","        \"LEGA_FIRST_NAME\": \"drop\",\n","        \"LEGA_LAST_NAME\": \"drop\",\n","        \"PREFERRED_LAST_NAME\": \"drop\",\n","        \"PREFERRED_FIRST_NAME\": \"drop\",\n","        \"DATE_OF_BIRTH\": \"drop\",\n","        \"GENDER\": \"drop\",\n","        \"NATIVE_LANGUAGE_CODES\": \"drop\",\n","        \"EMAIL_ADDRESS\": \"drop\",\n","        \"CURRENT_YEAR_GROUP\": \"drop\",\n","        \"CURRENT_REGISTRATION_GROUP\": \"drop\",\n","        \"GIFTED\": \"drop\",\n","        \"HAS_MEDICAL_CONDITION\": \"drop\",\n","        \"IN_YEAR_ADMISSION\": \"drop\",\n","        \"OUT_OF_AGE_GROUP_COHORT\": \"drop\",\n","        \"SEN\": \"drop\",\n","        \"TALENTED\": \"drop\",\n","        \"COMPULSORY_SCHOOL_AGE\": \"drop\",\n","        \"EARLY_YEARS_PUPIL_PREMIUM_RECIPIENT\": \"drop\",\n","        \"EVER_6_SERVICE_CHILD\": \"drop\",\n","        \"MOBILE_Y10_Y11\": \"drop\",\n","        \"MOBILE_Y5_Y6\": \"drop\",\n","        \"TRAVELLER\": \"drop\",\n","        \"DISADVANTAGED\": \"drop\",\n","        # Renames\n","        \"EAL\": {\"new_name\": \"English_As_Additional_Language\"}, \n","        \"IS_CURRENT\": {\"new_name\": \"Enrolment_Status\"}, \n","        \"ETHNICITY\": {\"new_name\": \"Ethnicity\"},\n","        \"RELIGION\": {\"new_name\":\"Religion\"},\n","        \"NATIONALITIES\": {\"new_name\": \"Nationality\"},\n","        \"IN_CARE\": {\"new_name\": \"In_Care\"}, \n","        \"NATIVE_LANGUAGE_NAMES\": {\"new_name\": \"First_Language\"}, \n","        \"FSM\": {\"new_name\": \"Free_School_Meals\"}, \n","        \"EVER_6_FSM\": {\"new_name\": \"Free_School_Meals_6\"}, \n","        \"GIFTED_TALENTED\": {\"new_name\": \"Gifted_And_Talented_Status\"}, \n","        \"PUPIL_PREMIUM_RECIPIENT\": {\"new_name\": \"Pupil_Premium_Indicator\"}, \n","        \"PUPIL_PREMIUM\": {\"new_name\": \"Pupil_Premium_Eligible\"}, \n","        \"CURRENT_SEN_STATUS\": {\"new_name\": \"SEN_Status\"}, \n","        \"SERVICE_CHILD\": {\"new_name\": \"Service_Child\"},            \n","        \"CHILD_PROTECTION\": {\"new_name\": \"Child_Protection_Plan\"},         \n","        \"STUDENT_ID\": {\"new_name\": \"student_id\"}, \n","        \"APPLICATION_ID\": {\"new_name\": \"school_id\"}, \n","        # adds\n","        \"add_columns\": {\n","            \"organisationkey\": \"\",\n","            \"studentextendedkey\": \"\",\n","            \"studentkey\": \"\",\n","            \"Ethnicity_Code\":\"\",\n","            \"In_LEA_Care\" :\"\", \n","            \"Leaver_Destination\" :\"\",\n","            \"Ever_In_Care\": \"\",\n","            \"Enrolment_Status\": \"\",\n","            \"Child_In_Need\": \"\",    \n","            \"Leaver_Destination\": \"\",\n","            \"In_LEA_Care\": \"\",\n","            \"Current_Year\": \"\",\n","            \"NC_Year\": \"\",\n","            \"unique_key\": \"\",\n","        }\n","    },\n","        \"attendancesession.csv\": {\n","        # drops\n","        \"ATTENDANCE_ROLL_CALL_RECORD_ID\":\"drop\",\n","        \"STUDENT_UNIQUE_ID\":\"drop\",\n","        \"APPLICATION_ID\":\"drop\",\n","        \"ATTENDANCE_ROLL_CALL_ID\":\"drop\",\n","        \"ATTENDANCE_ROLL_CALL_RECORD_UNIQUE_ID\":\"drop\",\n","        \"MARK_CODE\":\"drop\",\n","        \"MINUTES_LATE\":\"drop\",\n","        \"ACADEMIC_YEAR_NAME\":\"drop\",\n","        \"IS_PRESENT\":\"drop\",\n","        \"IS_AUTHORIZED_ABSENT\":\"drop\",\n","        \"IS_UNAUTHORIZED_ABSENT\":\"drop\",\n","        \"IS_POSSIBLE_ATTENDANCE\":\"drop\",\n","        # Renames \n","        \"DATE\": {\"new_name\": \"Date\"},  \n","        \"ATTENDANCE_ROLL_CALL_UNIQUE_ID\": {\"new_name\": \"school_id\"}, \n","        \"PERIOD\": {\"new_name\": \"Session\"}, \n","        \"RAW_MARK\": {\"new_name\": \"Mark\"},\n","        \"STUDENT_ID\": {\"new_name\": \"student_id\"}, \n","        # adds\n","        \"add_columns\": {\n","            \"organisationkey\": \"\",\n","            \"attendancesessionkey\": \"\",\n","            \"studentkey\": \"\",\n","            \"Comment\": \"\",\n","            \"staff_id\": \"\",\n","            \"last_updated\": \"\",\n","            \"unique_key\": \"\",\n","        }\n","    }\n","}"]},{"cell_type":"code","execution_count":null,"id":"bbefdff3-7784-4d50-9e2e-2ac20ee28683","metadata":{},"outputs":[],"source":["# Dictionary to hold dataframes for each csv file\n","csv_dfs = {}\n","temp_dfs = {}\n","all_columns = {}\n","'''\n","    This code is to loop through each csv file to compile into\n","    a list of dfs to process\n","\n","    It creates csv_dfs - a dictionary of the csv files\n","'''\n","# Consider only csv files that are in your mapping\n","csv_files = list(delta_table_name_mapping.keys())\n","\n","#print(list(delta_table_name_mapping.keys()))\n","for csv_file in csv_files:\n","    csv_file_path = f\"{bronze_path}/{csv_file}\"\n","    try:\n","        temp_df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n","        # Update the set of columns for the csv_file\n","        all_columns.setdefault(csv_file, set()).update(temp_df.columns)\n","        temp_dfs[csv_file] = temp_df\n","    except Exception as e:\n","        print(f\"An unexpected error occurred while processing {csv_dir_path}: {e}\")\n","        continue\n","# Assign the final json_dfs outside the loops\n","csv_dfs = temp_dfs"]},{"cell_type":"code","execution_count":null,"id":"f7c5e946-f2e3-4035-96fc-5d7953715d97","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["for csv_name, df in csv_dfs.items():\n","    if csv_name in column_mappings:\n","        df = oeai.apply_column_mappings(df, column_mappings[csv_name])\n","        csv_dfs[csv_name] = df  "]},{"cell_type":"code","execution_count":null,"id":"cd500daa-06ac-4421-b5d8-179972c9e5eb","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# add all the unique_keys\n","# schools.csv\n","df_schools = []\n","df_schools = csv_dfs['schools.csv']\n","df_schools = df_schools.withColumn(\"unique_key\", df_schools[\"school_id\"])\n","\n","# students.csv\n","df_stud = []\n","df_stud = csv_dfs['students.csv']\n","df_stud = df_stud.withColumn(\"unique_key\", concat_ws(\"_\",df_stud[\"school_id\"],df_stud[\"student_id\"] ))\n","\n","# students_extended.csv\n","df_studext = []\n","df_studext = csv_dfs['students_extended.csv']\n","df_studext = df_studext.withColumn(\"unique_key\", concat_ws(\"_\",df_studext[\"school_id\"],df_studext[\"student_id\"] ))\n","\n","# attendance.csv\n","df_att = []\n","df_att = csv_dfs['attendancesession.csv']\n","df_att = df_att.withColumn(\"unique_key\", df_att[\"school_id\"])"]},{"cell_type":"code","execution_count":null,"id":"ef4ece75-b093-481c-a1cf-acfa309adf9a","metadata":{"advisor":{"adviceMetadata":"{\"artifactId\":\"e08a073e-70e0-40fb-9366-f63d35e506fa\",\"activityId\":\"14833b89-9b01-4d0c-aad3-90400d1a9d55\",\"applicationId\":\"application_1705395807275_0001\",\"jobGroupId\":\"11\",\"advices\":{\"warn\":1}}"},"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Process each DataFrame and upsert it to the silver_path\n","for csv_name, df in csv_dfs.items():\n","    \n","    if csv_name in delta_table_name_mapping and delta_table_name_mapping[csv_name] != \"\":\n","        # Get the Delta table name from the mapping\n","        delta_table_name = delta_table_name_mapping[csv_name]\n","        silver_table_path = f\"{silver_path}/{delta_table_name}\"\n","        uuid_column_name = oeai.get_uuid_column_name(delta_table_name)\n","\n","        # Define the unique key column name\n","        unique_key_column = \"unique_key\"  \n","\n","        if delta_table_name == \"dim_Organisation\":\n","            if DeltaTable.isDeltaTable(spark, silver_table_path):\n","                delta_table = DeltaTable.forPath(spark, silver_table_path)\n","                \n","                # Alias the Delta table as 'target' and rename 'organisationkey' to 'target_organisationkey'\n","                target_df = delta_table.toDF().select(unique_key_column, col(\"organisationkey\").alias(\"target_organisationkey\"))\n","                \n","                # Alias the source DataFrame as 'source'\n","                source_df = df.alias(\"source\")\n","                \n","                # Perform a left join to find non-matched records\n","                df_with_keys = source_df.join(\n","                    target_df,\n","                    source_df[unique_key_column] == target_df[unique_key_column],\n","                    how=\"left\"\n","                ).select(\n","                    # Select all columns from 'source' EXCEPT 'organisationkey' if it exists\n","                    *[source_df[col].alias(col) for col in source_df.columns if col != \"organisationkey\"],\n","                    # Coalesce to get 'organisationkey' from 'target' if it exists, or generate a new one\n","                    coalesce(col(\"target_organisationkey\"), expr(\"uuid()\")).alias(\"organisationkey\")\n","                )\n","                \n","                # Now perform the merge operation\n","                delta_table.alias(\"target\").merge(\n","                    df_with_keys.alias(\"source\"),\n","                    f\"target.{unique_key_column} = source.{unique_key_column}\"\n","                ).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n","                \n","            else:\n","                # If the table does not exist, create it by writing the current DataFrame\n","                # First, add a column for the organisationkey for all records since this is a new table\n","                df = df.withColumn(\"organisationkey\", expr(\"uuid()\"))\n","                df.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)\n","        else:\n","            # Process student table before all others:\n","            if delta_table_name == \"dim_Student\":\n","                if DeltaTable.isDeltaTable(spark, silver_table_path):\n","                    delta_table = DeltaTable.forPath(spark, silver_table_path)\n","                    try:\n","                        update_columns = {col: f\"source.{col}\" for col in df.columns if col not in ['organisationkey', uuid_column_name]}\n","                        delta_table.alias(\"target\").merge(\n","                            df.alias(\"source\"),\n","                            f\"target.{unique_key_column} = source.{unique_key_column}\"\n","                        ).whenMatchedUpdate(set=update_columns  # Use the dictionary of columns to update\n","                        ).whenNotMatchedInsertAll().execute()\n","                    except Exception as e:\n","                        print(delta_table_name)\n","                        df.printSchema()\n","                        print(e)\n","                else:\n","                    # If the table does not exist, create it by writing the current DataFrame\n","                    df = df.withColumn(uuid_column_name, expr(\"uuid()\"))\n","                    # Load the dim_Organisation table to get the existing mappings\n","                    dim_org_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Organisation\").select(\"school_id\", \"organisationkey\")\n","                    # Perform a left join to find existing organisation keys\n","                    df_joined = df.alias(\"source\").join(\n","                        dim_org_df.alias(\"dim\"),\n","                        col(\"source.school_id\") == col(\"dim.school_id\"),\n","                        \"left\"\n","                    )\n","                    # Select all columns from df and only the 'organisationkey' from the dim_Organisation\n","                    df_with_keys = df_joined.select(\"source.*\", col(\"dim.organisationkey\").alias(\"dim_organisationkey\"))\n","                    # Fill in the missing keys with UUIDs\n","                    df_complete = df_with_keys.withColumn(\n","                        \"organisationkey\",\n","                        when(col(\"dim_organisationkey\").isNull(), expr(\"uuid()\")).otherwise(col(\"dim_organisationkey\"))\n","                    )\n","                    # Drop the 'dim_organisationkey' as it is no longer needed\n","                    df_final = df_complete.drop(\"dim_organisationkey\")\n","                    df_final.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)\n","            else: # if not the organisation or student table         \n","                \n","                if ('studentkey' in df.columns) and (delta_table_name != \"dim_Student\"):\n","                    # ------------------------------\n","                    # First, get the organisationkey\n","                    # ------------------------------\n","                    # Read the dim_Organisation table\n","                    dim_org_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Organisation\").select(\"school_id\", \"organisationkey\")\n","                    \n","                    df = df.drop(\"organisationkey\")\n","\n","                    # Perform a left join to find existing organisation keys\n","                    df_joined = df.alias(\"source\").join(\n","                        dim_org_df.alias(\"dim\"),\n","                        col(\"source.school_id\") == col(\"dim.school_id\"),\n","                        \"left\"\n","                    )\n","\n","                    # df_joined = df.drop(\"external_id\")\n","\n","                    # Select all columns from df (source) and only the 'organisationkey' from dim_Organisation (dim)\n","                    # Alias the dim_Organisation's organisationkey to avoid ambiguity\n","                    \n","                    df_with_orgkey = df_joined.select(\n","                        *[col(f\"source.{col_name}\") for col_name in df.columns],\n","                        col(\"dim.organisationkey\")\n","                    )\n","\n","                    # --------------------------\n","                    # second, get the studentkey\n","                    # --------------------------\n","                    \n","                    dim_student_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Student\").select(\"student_id\", \"organisationkey\", \"studentkey\")\n","                    # Rename the 'studentkey' column from dim_student_df to avoid ambiguity\n","                    dim_student_df = dim_student_df.withColumnRenamed(\"studentkey\", \"dim_studentkey\")\n","                    \n","                    # Perform a left join\n","                    df_studjoined = df_with_orgkey.alias(\"source\").join(\n","                        dim_student_df.alias(\"dim\"),\n","                        (trim(lower(col(\"source.student_id\"))) == trim(lower(col(\"dim.student_id\")))) &\n","                        (trim(lower(col(\"source.organisationkey\"))) == trim(lower(col(\"dim.organisationkey\")))),\n","                        \"left\"\n","                    )\n","                    \n","                    # Use when() to decide which studentkey to keep\n","                    df_both_keys = df_studjoined.withColumn(\"studentkey\", \n","                                            when(col(\"dim.dim_studentkey\").isNull(), col(\"source.studentkey\"))\n","                                            .otherwise(col(\"dim.dim_studentkey\"))\n","                                            ) \\\n","                                .drop(\"dim.dim_studentkey\") \\\n","                                .select(\"source.*\", \"studentkey\")\n","\n","                    df = df_both_keys\n","\n","                    # debug, show 20 records\n","                    #df.filter((col(\"studentkey\").isNotNull()) & (col(\"studentkey\") != \"\")).select(\"studentkey\").show(n=20, truncate=False)\n","\n","                # -------------------------------------------------------------------\n","                # Now that any table with student_id in it has studentkey continue...\n","                # -------------------------------------------------------------------\n","\n","                # Set the update columns to update everything other than organisationkey and the unique_key\n","                update_columns = {col: f\"source.{col}\" for col in df.columns if col not in ['organisationkey', uuid_column_name]}\n","                # print(update_columns)\n","\n","                if DeltaTable.isDeltaTable(spark, silver_table_path):\n","                    delta_table = DeltaTable.forPath(spark, silver_table_path)\n","                    try:\n","                        delta_table.alias(\"target\").merge(\n","                            df.alias(\"source\"),\n","                            f\"target.{unique_key_column} = source.{unique_key_column}\"\n","                        ).whenMatchedUpdate(set=update_columns  # Use the dictionary of columns to update\n","                        ).whenNotMatchedInsertAll().execute()\n","\n","                    except Exception as e:\n","                        print(delta_table_name)\n","                        df.printSchema()\n","                        print(e)\n","                    \n","                else:\n","                    # If the table does not exist, create it by writing the current DataFrame\n","                    # First, generate a UUID for all records in the new UUID column\n","                    df = df.withColumn(uuid_column_name, expr(\"uuid()\"))\n","\n","                    if ('studentkey' not in df.columns): # because we have already added organisationkey to that\n","                \n","                        # Load the dim_Organisation table to get the existing mappings\n","                        dim_org_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Organisation\").select(\"school_id\", \"organisationkey\")\n","\n","                        # Perform a left join to find existing organisation keys\n","                        df_joined = df.alias(\"source\").join(\n","                            dim_org_df.alias(\"dim\"),\n","                            col(\"source.school_id\") == col(\"dim.school_id\"),\n","                            \"left\"\n","                        )\n","\n","                        # Select all columns from df and only the 'organisationkey' from the dim_Organisation\n","                        # Alias the dim_Organisation's organisationkey to avoid ambiguity\n","                        df_with_keys = df_joined.select(\"source.*\", col(\"dim.organisationkey\").alias(\"dim_organisationkey\"))\n","                        df_with_keys.printSchema()\n","\n","                        # Fill in the missing keys with UUIDs\n","                        # Ensure to use the aliased column name 'dim_organisationkey' to avoid ambiguity\n","                        df_complete = df_with_keys.withColumn(\n","                            \"organisationkey\",\n","                            when(col(\"dim_organisationkey\").isNull(), expr(\"uuid()\")).otherwise(col(\"dim_organisationkey\"))\n","                        )\n","\n","                        # Drop the 'dim_organisationkey' as it is no longer needed\n","                        df = df_complete.drop(\"dim_organisationkey\")\n","\n","\n","                    # debug, show 20 records\n","                    df.show(n=20, truncate=False)\n","\n","                    df.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)"]}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python"},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default"},"synapse_widget":{"state":{},"version":"0.1"},"trident":{"lakehouse":{"known_lakehouses":[]}},"widgets":{}},"nbformat":4,"nbformat_minor":5}
