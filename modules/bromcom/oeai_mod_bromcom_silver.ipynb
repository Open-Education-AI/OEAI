{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-01-14T14:39:30.5182328Z",
              "session_start_time": null,
              "execution_start_time": "2024-01-14T14:40:32.9403165Z",
              "execution_finish_time": "2024-01-14T14:40:32.9405971Z",
              "spark_jobs": null,
              "parent_msg_id": "72b0b40a-4e92-4154-a613-5006af8e6baa"
            },
            "text/plain": "StatementMeta(, , -1, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "%run oeai_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "45",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-01-14T14:40:36.3647189Z",
              "session_start_time": null,
              "execution_start_time": "2024-01-14T14:40:36.4971604Z",
              "execution_finish_time": "2024-01-14T14:40:37.0697588Z",
              "spark_jobs": null,
              "parent_msg_id": "5fb3155a-069a-4274-911c-3b440de64ced"
            },
            "text/plain": "StatementMeta(spark3p3sm, 45, 3, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# CHANGE VALUES FOR YOUR KEY VAULT\r\n",
        "keyvault = \"kv-oea-dat\"  # change for your KV name\r\n",
        "keyvault_linked_service = \"LS_KeyVault\"  \r\n",
        "\r\n",
        "# Synapse OEA environment paths\r\n",
        "bronze_path = oeai.get_secret(spark, \"bromcom-bronze\", keyvault_linked_service, keyvault)\r\n",
        "silver_path = oeai.get_secret(spark, \"bromcom-silver\", keyvault_linked_service, keyvault)\r\n",
        "silver_ref_path = oeai.get_secret(spark, \"oeai-silver\", keyvault_linked_service, keyvault)\r\n",
        "gold_path = oeai.get_secret(spark, \"gold-path\", keyvault_linked_service, keyvault)\r\n",
        "school_ids_secret = oeai.get_secret(spark, \"bromcom-ids\", keyvault_linked_service, keyvault)\r\n",
        "subdirectories = school_ids_secret.split(\",\")\r\n",
        "appid = oeai.get_secret(spark, \"bromcom-appid\", keyvault_linked_service, keyvault)\r\n",
        "token = oeai.get_secret(spark, \"bromcom-appsecret\", keyvault_linked_service, keyvault)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "45",
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-01-14T14:41:08.2205477Z",
              "session_start_time": null,
              "execution_start_time": "2024-01-14T14:41:08.3705711Z",
              "execution_finish_time": "2024-01-14T14:41:08.5715444Z",
              "spark_jobs": null,
              "parent_msg_id": "10494645-fbab-493e-8d2d-f136da3d5301"
            },
            "text/plain": "StatementMeta(spark3p3sm, 45, 5, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Define the mapping between JSON files and desired Delta table names\r\n",
        "delta_table_name_mapping = {\r\n",
        "    #\"Schools.json\": \"dim_Organisation\",\r\n",
        "    #\"Students.json\": \"dim_Student\",\r\n",
        "    #\"StudentFlatView.json\": \"dim_StudentExtended\",\r\n",
        "    \"AttendanceSessions.json\": \"fact_AttendanceSummary\",\r\n",
        "    #\"Attendances.json\": \"fact_AttendanceSession\"\r\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "45",
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-01-14T14:41:12.7520755Z",
              "session_start_time": null,
              "execution_start_time": "2024-01-14T14:41:12.9004976Z",
              "execution_finish_time": "2024-01-14T14:41:13.1497006Z",
              "spark_jobs": null,
              "parent_msg_id": "cf33fe5b-5d01-4484-a2d9-8a1b56823b2a"
            },
            "text/plain": "StatementMeta(spark3p3sm, 45, 6, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "column_mappings = {\r\n",
        "    \"Schools.json\": {\r\n",
        "        # drops\r\n",
        "        \"postCode\": \"drop\", \r\n",
        "        \"nationalityDescription\": \"drop\",\r\n",
        "        \"town\": \"drop\",\r\n",
        "        \"locality\": \"drop\",\r\n",
        "        \"street\": \"drop\",\r\n",
        "        \"flatNameNumber\": \"drop\",\r\n",
        "        \"buildingNameNumber\": \"drop\",\r\n",
        "        \"administrativeArea\": \"drop\",\r\n",
        "        \"telephoneNumber\": \"drop\",\r\n",
        "        \"faxNumber\": \"drop\",\r\n",
        "        \"emailAddress\": \"drop\",\r\n",
        "        \"leaid\": \"drop\",\r\n",
        "        \"leaName\": \"drop\",\r\n",
        "        \"councilTaxReference\": \"drop\",\r\n",
        "        \"webSite\": \"drop\",\r\n",
        "        \"headTitle\": \"drop\",\r\n",
        "        \"headTeacherName\": \"drop\",\r\n",
        "        \"currentSchool\": \"drop\",\r\n",
        "        \"isPartOfMat\": \"drop\",\r\n",
        "        \"dateJoinedMAT\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"schoolID\": {\"new_name\": \"external_id\"}, \r\n",
        "        \"schoolName\": {\"new_name\": \"Organisation_Name\"},  \r\n",
        "        \"establishmentNumber\": {\"new_name\": \"Establishment_Number\"},  \r\n",
        "        \"uniqueReferenceNumber\": {\"new_name\": \"URN\"},\r\n",
        "        \"leaNumber\": {\"new_name\": \"LA_Code\"},\r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",  \r\n",
        "            \"addresskey\": \"\",  \r\n",
        "            \"UKPRN\": \"\",\r\n",
        "            \"Organisation_Status\": \"Active\",\r\n",
        "            \"last_updated\": \"\",\r\n",
        "        },\r\n",
        "    },\r\n",
        "    \"Students.json\": {   \r\n",
        "        # drops\r\n",
        "        \"admissionNumber\": \"drop\",\r\n",
        "        \"legalFullName\": \"drop\",\r\n",
        "        \"salutation\": \"drop\",\r\n",
        "        \"ethnicityID\": \"drop\",\r\n",
        "        \"bloodGroup\": \"drop\",\r\n",
        "        \"\": \"drop\",\r\n",
        "        \"upn\": \"drop\",\r\n",
        "        \"startDate\": \"drop\",\r\n",
        "        \"endDate\": \"drop\",\r\n",
        "        \"preferredFullName\": \"drop\",\r\n",
        "        \"formerLastName\": \"drop\",\r\n",
        "        \"nhsNumber\": \"drop\",\r\n",
        "        \"ethnicity\": \"drop\",\r\n",
        "        \"nationality\": \"drop\",\r\n",
        "        \"photoFileName\": \"drop\",\r\n",
        "        \"prefix\": \"drop\",\r\n",
        "        \"giftedAndTalented\": \"drop\",\r\n",
        "        \"englishProficiencyDescription\": \"drop\",\r\n",
        "        \"birthCertificateSeen\": \"drop\",\r\n",
        "        \"honours\": \"drop\",\r\n",
        "        \"formerUPN\": \"drop\",\r\n",
        "        \"uci\": \"drop\",        \r\n",
        "        \"uln\": \"drop\",\r\n",
        "        \"schoolUniqueReferenceNumber\": \"drop\",\r\n",
        "        \"examNumber\": \"drop\",\r\n",
        "        \"empty\": \"drop\",        \r\n",
        "        \"yearGroup\": \"drop\",\r\n",
        "        \"tutorGroup\": \"drop\",\r\n",
        "        \"yearGroupID\": \"drop\",\r\n",
        "        \"tutorGroupID\": \"drop\",\r\n",
        "        \"connexionsAgreementStateCode\": \"drop\",\r\n",
        "        \"connexionsAgreement\": \"drop\",\r\n",
        "        \"numberOfPositiveEvents\": \"drop\",\r\n",
        "        \"numberOfNegativeEvents\": \"drop\",\r\n",
        "        \"nCyearActual\": \"drop\",\r\n",
        "        \"isPregnantStudent\": \"drop\",\r\n",
        "        \"isStudentPaidUniformAllowance\": \"drop\",\r\n",
        "        \"familyStructureDescription\": \"drop\",\r\n",
        "        \"nationalCurriculumDescription\": \"drop\",\r\n",
        "        \"inYear\": \"drop\",\r\n",
        "        \"laInYearText\": \"drop\",\r\n",
        "        \"homeLA\": \"drop\",\r\n",
        "        \"recoupmentLA\": \"drop\",\r\n",
        "        \"twoYearOldFundTypeDescription\": \"drop\",\r\n",
        "        \"adoptedFromCareTypeName\": \"drop\",\r\n",
        "        \"adoptedFromCareTypeDescription\": \"drop\",\r\n",
        "        \"pupilPremiumFlag\": \"drop\",\r\n",
        "        \"everFSM6Flag\": \"drop\",\r\n",
        "        \"chronologicalYeargroup\": \"drop\",\r\n",
        "        \"mailingPoint\": \"drop\",\r\n",
        "        \"thirtyHourCode\": \"drop\",\r\n",
        "        \"hasDisabilityLivingAllowance\": \"drop\",\r\n",
        "        \"hasFreeEarlyEducation\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"studentID\": {\"new_name\": \"student_id\"}, \r\n",
        "        \"dateOfBirth\": {\"new_name\": \"Date_Of_Birth\"}, \r\n",
        "        \"preferredFirstName\": {\"new_name\": \"Forename\"}, \r\n",
        "        \"gender\": {\"new_name\": \"Gender\"}, \r\n",
        "        \"firstName\": {\"new_name\": \"Legal_Forename\"}, \r\n",
        "        \"lastName\": {\"new_name\": \"Legal_Surname\"}, \r\n",
        "        \"middleName\": {\"new_name\": \"Middle_Names\"}, \r\n",
        "        \"preferredlastName\": {\"new_name\": \"Surname\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "            \"last_updated\": \"\",\r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"AttendanceSessions.json\": {\r\n",
        "        # drops\r\n",
        "        \"created_at\": \"drop\",\r\n",
        "        \"year\": \"drop\",      \r\n",
        "        \"establishmentNumber\": \"drop\",\r\n",
        "        \"lea\": \"drop\",\r\n",
        "        \"leaDescription\": \"drop\",\r\n",
        "        \"schoolName\": \"drop\", \r\n",
        "        \"attendanceStartDate\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"attendanceMarks\": {\"new_name\": \"Attendance_Mark_String\"}, \r\n",
        "        \"studentID\": {\"new_name\": \"student_id\"}, \r\n",
        "        \"authorised\": {\"new_name\": \"Authorised_Absences\"}, \r\n",
        "        \"possible\": {\"new_name\": \"Possible_marks\"}, \r\n",
        "        \"attended\": {\"new_name\": \"Present\"}, \r\n",
        "        \"unauthorised\": {\"new_name\": \"Unauthorised_Absences\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"attendancesummarykey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "            \"approved_education_activity\": \"\",\r\n",
        "            \"last_updated\": \"\",\r\n",
        "            \"id\": \"\", \r\n",
        "            \"late_after_registration\": \"\", \r\n",
        "            \"late_before_registration\": \"\", \r\n",
        "            \"missing_marks\": \"\", \r\n",
        "            \"unexplained_absences\": \"\", \r\n",
        "            \"updated_at\": \"\", \r\n",
        "        }\r\n",
        "    },\r\n",
        "    \"StudentFlatView.json\": {\r\n",
        "        # drops\r\n",
        "        \"yssaName\": \"drop\",\r\n",
        "        \"yssaDescription\": \"drop\",\r\n",
        "        \"usualMealDescription\": \"drop\",\r\n",
        "        \"uniqueLearnerNumber\": \"drop\",\r\n",
        "        \"unauthorisedAttendancePercentageClass\": \"drop\",\r\n",
        "        \"unauthorisedAttendancePercentageAMPM\": \"drop\",\r\n",
        "        \"unauthorisedAttendanceCountClass\": \"drop\",\r\n",
        "        \"unauthorisedAttendanceCountAMPM\": \"drop\",\r\n",
        "        \"uci\": \"drop\",\r\n",
        "        \"tutorNames\": \"drop\",\r\n",
        "        \"tutorGroupName\": \"drop\",\r\n",
        "        \"travelModeDescription\": \"drop\",\r\n",
        "        \"totalNumberOfExcludedDays\": \"drop\",\r\n",
        "        \"totalMinutesLateClass\": \"drop\",\r\n",
        "        \"totalMinutesLateAMPM\": \"drop\",\r\n",
        "        \"systemDate\": \"drop\",\r\n",
        "        \"surgeryName\": \"drop\",\r\n",
        "        \"surgeryDescription\": \"drop\",\r\n",
        "        \"studentTelephone\": \"drop\",\r\n",
        "        \"studentSiblingListOnRoll\": \"drop\",\r\n",
        "        \"studentSiblingList\": \"drop\",\r\n",
        "        \"studentMainTown\": \"drop\",\r\n",
        "        \"studentMainStreet\": \"drop\",\r\n",
        "        \"studentMainPostCode\": \"drop\",\r\n",
        "        \"studentMainFlatNameNumber\": \"drop\",\r\n",
        "        \"studentMainBuildingNameNumber\": \"drop\",\r\n",
        "        \"studentMainAdministrativeArea\": \"drop\",\r\n",
        "        \"studentMainAddress\": \"drop\",\r\n",
        "        \"admissionNumber\": \"drop\",\r\n",
        "        \"adoptedFromCareTypeDescription\": \"drop\",\r\n",
        "        \"adoptedFromCareTypeName\": \"drop\",\r\n",
        "        \"ageYears\": \"drop\",\r\n",
        "        \"ageYearsMonths\": \"drop\",\r\n",
        "        \"allAbsencesAttendanceCountAMPM\": \"drop\",\r\n",
        "        \"allAbsencesAttendanceCountClass\": \"drop\",\r\n",
        "        \"allAbsencesAttendancePercentageClass\": \"drop\",\r\n",
        "        \"allAbsencesPercentageAMPM\": \"drop\",\r\n",
        "        \"attainmentLevelCode\": \"drop\",\r\n",
        "        \"attainmentLevelDescription\": \"drop\",\r\n",
        "        \"attendanceModeDescription\": \"drop\",\r\n",
        "        \"attendancePercentageClassWithEA\": \"drop\",\r\n",
        "        \"attendancePercentageClassnoEA\": \"drop\",\r\n",
        "        \"authorisedAttendanceCountAMPM\": \"drop\",\r\n",
        "        \"authorisedAttendanceCountClass\": \"drop\",\r\n",
        "        \"authorisedAttendancePercentageAMPM\": \"drop\",\r\n",
        "        \"authorisedAttendancePercentageClass\": \"drop\",\r\n",
        "        \"birthCertificateSeen\": \"drop\",\r\n",
        "        \"birthCountryDescription\": \"drop\",\r\n",
        "        \"birthCountryName\": \"drop\",\r\n",
        "        \"boarderStatusCode\": \"drop\",\r\n",
        "        \"boarderStatusDescription\": \"drop\",\r\n",
        "        \"carePlan\": \"drop\",\r\n",
        "        \"carePlanStartDate\": \"drop\",\r\n",
        "        \"careTypeName\": \"drop\",\r\n",
        "        \"caringAuthority\": \"drop\",\r\n",
        "        \"chronologicalYeargroup\": \"drop\",\r\n",
        "        \"contact1Details\": \"drop\",\r\n",
        "        \"contact1Email\": \"drop\",\r\n",
        "        \"contact1Name\": \"drop\",\r\n",
        "        \"contact1ParentalResponsibility\": \"drop\",\r\n",
        "        \"contact1Relationship\": \"drop\",\r\n",
        "        \"contact1Telephone\": \"drop\",\r\n",
        "        \"contact2Details\": \"drop\",\r\n",
        "        \"contact2Email\": \"drop\",\r\n",
        "        \"contact2Name\": \"drop\",\r\n",
        "        \"contact2ParentalResponsibility\": \"drop\",\r\n",
        "        \"contact2Relationship\": \"drop\",\r\n",
        "        \"contact2Telephone\": \"drop\",\r\n",
        "        \"contact3Details\": \"drop\",\r\n",
        "        \"contact3Email\": \"drop\",\r\n",
        "        \"contact3Name\": \"drop\",\r\n",
        "        \"contact3ParentalResponsibility\": \"drop\",\r\n",
        "        \"contact3Relationship\": \"drop\",\r\n",
        "        \"contact3Telephone\": \"drop\",\r\n",
        "        \"countryArrivalDate\": \"drop\",\r\n",
        "        \"dateOfBirth\": \"drop\",\r\n",
        "        \"dateOfEntry\": \"drop\",\r\n",
        "        \"daysToBirthday\": \"drop\",\r\n",
        "        \"disabilityDescription\": \"drop\",\r\n",
        "        \"disabilityName\": \"drop\",\r\n",
        "        \"doctorFirstName\": \"drop\",\r\n",
        "        \"doctorLastname\": \"drop\",\r\n",
        "        \"dualRegisteredWith\": \"drop\",\r\n",
        "        \"educationalActivityAttendanceCountAMPM\": \"drop\",\r\n",
        "        \"educationalActivityAttendanceCountClass\": \"drop\",\r\n",
        "        \"educationalActivityAttendancePercentageAMPM\": \"drop\",\r\n",
        "        \"educationalActivityAttendancePercentageClass\": \"drop\",\r\n",
        "        \"emergencyConsent\": \"drop\",\r\n",
        "        \"examNumber\": \"drop\",\r\n",
        "        \"firstName\": \"drop\",\r\n",
        "        \"formerUPN\": \"drop\",\r\n",
        "        \"genderCode\": \"drop\",\r\n",
        "        \"genderDescription\": \"drop\",\r\n",
        "        \"gypsyCodeName\": \"drop\",\r\n",
        "        \"hasContactWithCorrespondence\": \"drop\",\r\n",
        "        \"heSheCapitalised\": \"drop\",\r\n",
        "        \"headOfHouse\": \"drop\",\r\n",
        "        \"headOfYear\": \"drop\",\r\n",
        "        \"heshe\": \"drop\",\r\n",
        "        \"himHer\": \"drop\",\r\n",
        "        \"hisHer\": \"drop\",\r\n",
        "        \"hisHerCapitalised\": \"drop\",\r\n",
        "        \"homeLanguage\": \"drop\",\r\n",
        "        \"houseName\": \"drop\",\r\n",
        "        \"isDataProcessingConsentGranted\": \"drop\",\r\n",
        "        \"isDeprivationPupilPremium\": \"drop\",\r\n",
        "        \"isEarlyYearPupilPremium\": \"drop\",\r\n",
        "        \"isMobile\": \"drop\",\r\n",
        "        \"kS1MathsScaledScore\": \"drop\",\r\n",
        "        \"kS1ReadingScaledScore\": \"drop\",\r\n",
        "        \"kS2MathsScaledScore\": \"drop\",\r\n",
        "        \"kS2ReadingScaledScore\": \"drop\",\r\n",
        "        \"lastName\": \"drop\",\r\n",
        "        \"lateAttendanceCountAMPM\": \"drop\",\r\n",
        "        \"lateAttendanceCountClass\": \"drop\",\r\n",
        "        \"leavingReasonDescription\": \"drop\",\r\n",
        "        \"legalFullName\": \"drop\",\r\n",
        "        \"mainTutor\": \"drop\",\r\n",
        "        \"mainTutorStaffCode\": \"drop\",\r\n",
        "        \"medicalConditionTypesList\": \"drop\",\r\n",
        "        \"medicalConditionsList\": \"drop\",\r\n",
        "        \"medicalConditionsNotesList\": \"drop\",\r\n",
        "        \"middleName\": \"drop\",\r\n",
        "        \"monthofBirthName\": \"drop\",\r\n",
        "        \"monthofBirthNumber\": \"drop\",\r\n",
        "        \"nationalityDescription\": \"drop\",\r\n",
        "        \"nationalityName\": \"drop\",\r\n",
        "        \"notes\": \"drop\",\r\n",
        "        \"numberOfExcludedSessions\": \"drop\",\r\n",
        "        \"onReportDescription\": \"drop\",\r\n",
        "        \"onReportReasonDescription\": \"drop\",\r\n",
        "        \"parentalAddressee\": \"drop\",\r\n",
        "        \"parentalSalutation\": \"drop\",\r\n",
        "        \"personalEducationPlan\": \"drop\",\r\n",
        "        \"phonicsScreeningCheckMark\": \"drop\",\r\n",
        "        \"phonicsScreeningCheckOutcome\": \"drop\",\r\n",
        "        \"plannedLearningHoursYear\": \"drop\",\r\n",
        "        \"possiblesAttendanceCountAMPM\": \"drop\",\r\n",
        "        \"possiblesAttendanceCountClass\": \"drop\",\r\n",
        "        \"preferredFirstName\": \"drop\",\r\n",
        "        \"preferredFullName\": \"drop\",\r\n",
        "        \"preferredLastName\": \"drop\",\r\n",
        "        \"presentAttendanceCountClass\": \"drop\",\r\n",
        "        \"presentEACountAMPM\": \"drop\",\r\n",
        "        \"presentPercentageWithEA\": \"drop\",\r\n",
        "        \"previousPhaseSchool\": \"drop\",\r\n",
        "        \"previousSchool\": \"drop\",\r\n",
        "        \"privateNotes\": \"drop\",\r\n",
        "        \"provisionDescription\": \"drop\",\r\n",
        "        \"provisionName\": \"drop\",\r\n",
        "        \"provisionStartDate\": \"drop\",\r\n",
        "        #\"provisionEndDate\": \"drop\",\r\n",
        "        \"recoupmentLA\": \"drop\",\r\n",
        "        \"refugeeAsylumSeekerTypeName\": \"drop\",\r\n",
        "        \"religiousAffiliationDescription\": \"drop\",\r\n",
        "        \"reviewDate\": \"drop\",\r\n",
        "        \"route\": \"drop\",\r\n",
        "        \"secondLanguage\": \"drop\",\r\n",
        "        \"serviceChildrenInEducationDescription\": \"drop\",\r\n",
        "        \"sonDaughterCapitalised\": \"drop\",\r\n",
        "        \"sondaughter\": \"drop\",\r\n",
        "        \"sourceOfServiceChildrenInEducationCode\": \"drop\",\r\n",
        "        \"sourceOfServiceChildrenInEducationDescription\": \"drop\",\r\n",
        "        \"standardAdmissionTime\": \"drop\",\r\n",
        "        \"standardLeavingTime\": \"drop\",\r\n",
        "        \"studentContactCount\": \"drop\",\r\n",
        "        \"studentContactList\": \"drop\",\r\n",
        "        \"studentEmail\": \"drop\",\r\n",
        "        \"serviceChildrenInEducationCode\": \"drop\",\r\n",
        "        \"disadvantagedStudentsFlag\": \"drop\",\r\n",
        "        \"enrolmentEndDate\": \"drop\",\r\n",
        "        \"enrolmentStartDate\": \"drop\",\r\n",
        "        \"enrolmentStateDescription\": \"drop\",\r\n",
        "        \"fsmStartDate\": \"drop\",\r\n",
        "        \"hasEverLeft\": \"drop\",\r\n",
        "        \"isEligibleForFreeMeal\": \"drop\",\r\n",
        "        \"isLeaver\": \"drop\",\r\n",
        "        \"isLookedAfterPremium\": \"drop\",\r\n",
        "        \"nonQualificationPlannedHours\": \"drop\",\r\n",
        "        \"onReportStartDate\": \"drop\",\r\n",
        "        \"provisionReviewDate\": \"drop\",\r\n",
        "        \"qualificationPlannedHours\": \"drop\",\r\n",
        "        \"senNeedList\": \"drop\",\r\n",
        "        \"senPrimaryNeedDescription\": \"drop\",\r\n",
        "        \"status\": \"drop\",\r\n",
        "        \"studentMainLocality\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"yearGroup\": {\"new_name\": \"Current_Year\"}, \r\n",
        "        \"upn\": {\"new_name\": \"UPN\"}, \r\n",
        "        \"Student_ID\": {\"new_name\": \"student_id\"}, \r\n",
        "        \"destinationSchool\": {\"new_name\": \"Leaver_Destination\"}, \r\n",
        "        \"dateOfLeaving\": {\"new_name\": \"Leaving_Date\"},\r\n",
        "        \"ethnicityCode\": {\"new_name\": \"Ethnicity_Code\"}, \r\n",
        "        \"ethnicityDescription\": {\"new_name\": \"Ethnicity\"}, \r\n",
        "        \"firstLanguage\": {\"new_name\": \"First_Language\"},\r\n",
        "        \"ealFlag\": {\"new_name\": \"English_As_Additional_Language\"}, \r\n",
        "        \"enrolmentStateName\": {\"new_name\": \"Enrolment_Status\"},         \r\n",
        "        \"fsmIsActive\": {\"new_name\": \"Free_School_Meals\"},\r\n",
        "        \"isServiceChildPremium\": {\"new_name\": \"Service_Child_Indicator\"}, \r\n",
        "        \"everFSM6Flag\": {\"new_name\": \"Free_School_Meals_6\"}, \r\n",
        "        \"inCareFlag\": {\"new_name\": \"In_LEA_Care\"}, \r\n",
        "        \"gntFlag\": {\"new_name\": \"Gifted_And_Talented_Status\"}, \r\n",
        "        \"premiumPupilFlag\": {\"new_name\": \"Pupil_Premium_Indicator\"},\r\n",
        "        \"senPrimaryNeedCode\": {\"new_name\": \"SEN_Status\"}, \r\n",
        "        \"isAdoptedFromCarePremium\": {\"new_name\": \"Ever_In_Care\"},\r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"studentextendedkey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "        }\r\n",
        "    }, \r\n",
        "    \"Attendances.json\": {\r\n",
        "        # drops\r\n",
        "        \"attendanceCommentInstant\": \"drop\",\r\n",
        "        \"calendarEndDate\": \"drop\",\r\n",
        "        \"calendarID\": \"drop\",\r\n",
        "        \"calendarModelID\": \"drop\",\r\n",
        "        \"calendarName\": \"drop\",\r\n",
        "        \"collectionID\": \"drop\",\r\n",
        "        \"recordedOn\": \"drop\",\r\n",
        "        \"minute\": \"drop\",\r\n",
        "        \"markSubcode\": \"drop\",\r\n",
        "        \"markMeaningName\": \"drop\",\r\n",
        "        \"locationID\": \"drop\",\r\n",
        "        \"exportMark\": \"drop\",\r\n",
        "        \"markMeaningDescription\": \"drop\",\r\n",
        "        # Renames\r\n",
        "        \"mark\": {\"new_name\": \"Mark\"},  \r\n",
        "        \"attendanceComment\": {\"new_name\": \"Comment\"}, \r\n",
        "        \"calendarStartDate\": {\"new_name\": \"Date\"}, \r\n",
        "        \"recordedBy\": {\"new_name\": \"staff_id\"}, \r\n",
        "        \"attendanceID\": {\"new_name\": \"external_id\"}, \r\n",
        "        \"studentID\": {\"new_name\": \"student_id\"}, \r\n",
        "        # adds\r\n",
        "        \"add_columns\": {\r\n",
        "            \"organisationkey\": \"\",\r\n",
        "            \"attendancesessionkey\": \"\",\r\n",
        "            \"studentkey\": \"\",\r\n",
        "            \"session\": \"\",\r\n",
        "        }\r\n",
        "    },\r\n",
        "}    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "45",
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-01-14T14:41:19.4140802Z",
              "session_start_time": null,
              "execution_start_time": "2024-01-14T14:41:19.5496351Z",
              "execution_finish_time": "2024-01-14T14:41:34.6156306Z",
              "spark_jobs": null,
              "parent_msg_id": "e2fe36c2-a954-4510-a072-d07c046c7286"
            },
            "text/plain": "StatementMeta(spark3p3sm, 45, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame 'StudentFlatView.json' does not exist in temp_dfs\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Dictionary to hold dataframes for each json file\r\n",
        "json_dfs = {}\r\n",
        "temp_dfs = {}\r\n",
        "all_columns = {}\r\n",
        "'''\r\n",
        "    This code is to loop through each directory and compile all the individual schools jsons into\r\n",
        "    a single json per endpoint.\r\n",
        "\r\n",
        "    It creates json_dfs - a dictionary of the aggregated json files\r\n",
        "'''\r\n",
        "for subdir in subdirectories:\r\n",
        "    school_dir = f\"{bronze_path}{subdir}/\"\r\n",
        "\r\n",
        "    # Consider only JSON files that are in your mapping\r\n",
        "    json_dirs = list(delta_table_name_mapping.keys())\r\n",
        "    #print(\"json_dirs: \" ,json_dirs)\r\n",
        "\r\n",
        "    #print(list(delta_table_name_mapping.keys()))\r\n",
        "    for json_dir in json_dirs:\r\n",
        "        json_dir_path = f\"{school_dir}{json_dir}/\"\r\n",
        "        try:\r\n",
        "            temp_df = spark.read.json(json_dir_path)\r\n",
        "            temp_df = temp_df.withColumn(\"school_id\", lit(subdir))\r\n",
        "            # Update the set of columns for the json_dir\r\n",
        "            all_columns.setdefault(json_dir, set()).update(temp_df.columns)\r\n",
        "\r\n",
        "            # Check if json_dir already exists in temp_dfs dictionary\r\n",
        "            if json_dir in temp_dfs:\r\n",
        "                # Align the schema of temp_df with existing DataFrame in temp_dfs\r\n",
        "                existing_columns = all_columns[json_dir]\r\n",
        "                #print(existing_columns)\r\n",
        "                temp_df = oeai.add_missing_columns(temp_df, existing_columns)\r\n",
        "                existing_df = oeai.add_missing_columns(temp_dfs[json_dir], temp_df.columns)\r\n",
        "\r\n",
        "                # Perform the union operation\r\n",
        "                try:\r\n",
        "                    temp_df = oeai.match_column_types(existing_df, temp_df)\r\n",
        "                    temp_dfs[json_dir] = existing_df[sorted(existing_df.columns)].unionByName(temp_df[sorted(temp_df.columns)])\r\n",
        "                except Exception as e:\r\n",
        "                    print(\"An unexpected error occurred:\", e)\r\n",
        "\r\n",
        "            else:\r\n",
        "                # If not, simply assign temp_df to temp_dfs[json_dir]\r\n",
        "                temp_dfs[json_dir] = temp_df\r\n",
        "            \r\n",
        "        except AnalysisException as e:\r\n",
        "            print(f\"Path does not exist: {json_dir_path}, skipping...\")\r\n",
        "            continue\r\n",
        "        \r\n",
        "        except Exception as e:\r\n",
        "            print(f\"An unexpected error occurred while processing {json_dir_path}: {e}\")\r\n",
        "            continue\r\n",
        "\r\n",
        "if \"StudentFlatView.json\" in temp_dfs:\r\n",
        "    # Perform the dropDuplicates operation - this is because the Bromcom enpoint supplies dupes for records with different QualificationHours\r\n",
        "    temp_dfs[\"StudentFlatView.json\"] = temp_dfs[\"StudentFlatView.json\"].dropDuplicates([\"school_id\", \"student_ID\"])\r\n",
        "else:\r\n",
        "    # Handle the case where the DataFrame does not exist\r\n",
        "    print(\"DataFrame 'StudentFlatView.json' does not exist in temp_dfs\")\r\n",
        "\r\n",
        "# Assign the final json_dfs outside the loops\r\n",
        "json_dfs = temp_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "45",
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-01-14T14:41:37.6411409Z",
              "session_start_time": null,
              "execution_start_time": "2024-01-14T14:41:37.7792578Z",
              "execution_finish_time": "2024-01-14T14:41:37.9552117Z",
              "spark_jobs": null,
              "parent_msg_id": "bba868e1-5219-4f11-a3ff-bb3b7736efc9"
            },
            "text/plain": "StatementMeta(spark3p3sm, 45, 8, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "for json_name, df in json_dfs.items():\r\n",
        "    if json_name in column_mappings:\r\n",
        "        df = oeai.apply_column_mappings(df, column_mappings[json_name])\r\n",
        "        json_dfs[json_name] = df  # Update the dictionary with the new DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "45",
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-01-14T14:43:14.6439317Z",
              "session_start_time": null,
              "execution_start_time": "2024-01-14T14:43:14.8113134Z",
              "execution_finish_time": "2024-01-14T14:43:14.9872519Z",
              "spark_jobs": null,
              "parent_msg_id": "aca5d745-d739-4877-967e-668e5260b830"
            },
            "text/plain": "StatementMeta(spark3p3sm, 45, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Attendances.json' does not exist in json_dfs\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Modify and dataframes to match the Silver Schema\r\n",
        "\r\n",
        "if \"Attendances.json\" in json_dfs:\r\n",
        "    df_attendancesession = json_dfs['Attendances.json']\r\n",
        "    df_attendancesession = df_attendancesession.withColumn(\"Hour\", hour(\"Date\"))\r\n",
        "    # Step 2: Determine AM or PM and Update the Session Field\r\n",
        "    df_attendancesession = df_attendancesession.withColumn(\"session\", when(col(\"Hour\") < 12, \"AM\").otherwise(\"PM\"))\r\n",
        "    df_attendancesession = df_attendancesession.drop(\"Hour\")\r\n",
        "\r\n",
        "    df_attendancesession = df_attendancesession.withColumn(\"Time\", date_format(col(\"Date\"), \"HH:mm:ss\"))\r\n",
        "    df_attendancesession = df_attendancesession.withColumn(\"Date\", date_format(col(\"Date\"), \"yyyy-MM-dd\"))\r\n",
        "\r\n",
        "\r\n",
        "    df_joined = []\r\n",
        "    # Read the attendancecodes lookupup table\r\n",
        "    attendancecodes_path = silver_ref_path + \"dim_AttendanceCodes.csv\"\r\n",
        "    df_codes = spark.read.csv(attendancecodes_path, header=True, inferSchema=True)\r\n",
        "\r\n",
        "    df_joined = df_attendancesession.join(\r\n",
        "        df_codes.select('Mark', 'is_present', 'is_aea', 'is_auth', 'is_unauth', 'is_nr', 'is_poss', 'is_attend'),\r\n",
        "        on='Mark',  # column name to join on, which must be present in both DataFrames\r\n",
        "        how='inner'  # you can also use 'left', 'right', or 'outer' as needed\r\n",
        "    )\r\n",
        "\r\n",
        "    json_dfs['Attendances.json'] = df_joined\r\n",
        "    json_dfs['Attendances.json'].printSchema()\r\n",
        "else:\r\n",
        "    # Handle the case where the DataFrame does not exist\r\n",
        "    print(\"'Attendances.json' does not exist in json_dfs\")\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "45",
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2024-01-14T14:43:22.9299491Z",
              "session_start_time": null,
              "execution_start_time": "2024-01-14T14:43:23.0795047Z",
              "execution_finish_time": "2024-01-14T14:43:48.7754909Z",
              "spark_jobs": null,
              "parent_msg_id": "59145316-748a-4e8e-ae20-1f9fd3473232"
            },
            "text/plain": "StatementMeta(spark3p3sm, 45, 11, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Process each DataFrame and upsert it to the silver_path\r\n",
        "for json_name, df in json_dfs.items():\r\n",
        "    if json_name in delta_table_name_mapping and delta_table_name_mapping[json_name] != \"\":\r\n",
        "        # Get the Delta table name from the mapping\r\n",
        "        delta_table_name = delta_table_name_mapping[json_name]\r\n",
        "        silver_table_path = f\"{silver_path}/{delta_table_name}\"\r\n",
        "        uuid_column_name = oeai.get_uuid_column_name(delta_table_name)\r\n",
        "        # Define the unique key column name\r\n",
        "        unique_key_column = \"unique_key\"  \r\n",
        "        if delta_table_name == \"dim_Organisation\":\r\n",
        "            if DeltaTable.isDeltaTable(spark, silver_table_path):\r\n",
        "                delta_table = DeltaTable.forPath(spark, silver_table_path)\r\n",
        "                \r\n",
        "                # Alias the Delta table as 'target' and rename 'organisationkey' to 'target_organisationkey'\r\n",
        "                target_df = delta_table.toDF().select(unique_key_column, col(\"organisationkey\").alias(\"target_organisationkey\"))\r\n",
        "                \r\n",
        "                # Alias the source DataFrame as 'source'\r\n",
        "                source_df = df.alias(\"source\")\r\n",
        "                \r\n",
        "                # Perform a left join to find non-matched records\r\n",
        "                df_with_keys = source_df.join(\r\n",
        "                    target_df,\r\n",
        "                    source_df[unique_key_column] == target_df[unique_key_column],\r\n",
        "                    how=\"left\"\r\n",
        "                ).select(\r\n",
        "                    # Select all columns from 'source' EXCEPT 'organisationkey' if it exists\r\n",
        "                    *[source_df[col].alias(col) for col in source_df.columns if col != \"organisationkey\"],\r\n",
        "                    # Coalesce to get 'organisationkey' from 'target' if it exists, or generate a new one\r\n",
        "                    coalesce(col(\"target_organisationkey\"), expr(\"uuid()\")).alias(\"organisationkey\")\r\n",
        "                )\r\n",
        "                # Now perform the merge operation\r\n",
        "                delta_table.alias(\"target\").merge(\r\n",
        "                    df_with_keys.alias(\"source\"),\r\n",
        "                    f\"target.{unique_key_column} = source.{unique_key_column}\"\r\n",
        "                ).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\r\n",
        "                \r\n",
        "            else:\r\n",
        "                # If the table does not exist, create it by writing the current DataFrame\r\n",
        "                # First, add a column for the organisationkey for all records since this is a new table\r\n",
        "                df = df.withColumn(\"organisationkey\", expr(\"uuid()\"))\r\n",
        "                df.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)\r\n",
        "        else:\r\n",
        "            # Process student table before all others:\r\n",
        "            if delta_table_name == \"dim_Student\":\r\n",
        "                if DeltaTable.isDeltaTable(spark, silver_table_path):\r\n",
        "                    delta_table = DeltaTable.forPath(spark, silver_table_path)\r\n",
        "                    try:\r\n",
        "                        update_columns = {col: f\"source.{col}\" for col in df.columns if col not in ['organisationkey', uuid_column_name]}\r\n",
        "                        delta_table.alias(\"target\").merge(\r\n",
        "                            df.alias(\"source\"),\r\n",
        "                            f\"target.{unique_key_column} = source.{unique_key_column}\"\r\n",
        "                        ).whenMatchedUpdate(set=update_columns  # Use the dictionary of columns to update\r\n",
        "                        ).whenNotMatchedInsertAll().execute()\r\n",
        "                    except Exception as e:\r\n",
        "                        print(delta_table_name)\r\n",
        "                        df.printSchema()\r\n",
        "                        print(e)\r\n",
        "                else:\r\n",
        "                    # If the table does not exist, create it by writing the current DataFrame\r\n",
        "                    df = df.withColumn(uuid_column_name, expr(\"uuid()\"))\r\n",
        "                    #df.printSchema()\r\n",
        "                    # Load the dim_Organisation table to get the existing mappings\r\n",
        "                    dim_org_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Organisation\").select(\"school_id\", \"organisationkey\")\r\n",
        "                    # Perform a left join to find existing organisation keys\r\n",
        "                    df_joined = df.alias(\"source\").join(\r\n",
        "                        dim_org_df.alias(\"dim\"),\r\n",
        "                        col(\"source.school_id\") == col(\"dim.school_id\"),\r\n",
        "                        \"left\"\r\n",
        "                    )\r\n",
        "                    # Select all columns from df and only the 'organisationkey' from the dim_Organisation\r\n",
        "                    df_with_keys = df_joined.select(\"source.*\", col(\"dim.organisationkey\").alias(\"dim_organisationkey\"))\r\n",
        "                    #df_with_keys.printSchema()\r\n",
        "                    # Fill in the missing keys with UUIDs\r\n",
        "                    df_complete = df_with_keys.withColumn(\r\n",
        "                        \"organisationkey\",\r\n",
        "                        when(col(\"dim_organisationkey\").isNull(), expr(\"uuid()\")).otherwise(col(\"dim_organisationkey\"))\r\n",
        "                    )\r\n",
        "                    # Drop the 'dim_organisationkey' as it is no longer needed\r\n",
        "                    df_final = df_complete.drop(\"dim_organisationkey\")\r\n",
        "                    #df_final.printSchema()\r\n",
        "                    df_final.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)\r\n",
        "            else: # if not the organisation or student table         \r\n",
        "                \r\n",
        "                if ('studentkey' in df.columns) and (delta_table_name != \"dim_Student\"):\r\n",
        "                    # ------------------------------\r\n",
        "                    # First, get the organisationkey\r\n",
        "                    # ------------------------------\r\n",
        "                    #print(delta_table_name)\r\n",
        "                    # Read the dim_Organisation table\r\n",
        "                    dim_org_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Organisation\").select(\"school_id\", \"organisationkey\")\r\n",
        "                    df = df.drop(\"organisationkey\")\r\n",
        "\r\n",
        "                    #print(\"This is the original schema for df\")\r\n",
        "                    #df.printSchema()\r\n",
        "                    \r\n",
        "                    # Perform a left join to find existing organisation keys\r\n",
        "                    df_joined = df.alias(\"source\").join(\r\n",
        "                        dim_org_df.alias(\"dim\"),\r\n",
        "                        col(\"source.school_id\") == col(\"dim.school_id\"),\r\n",
        "                        \"left\"\r\n",
        "                    )\r\n",
        "\r\n",
        "                    # df_joined = df.drop(\"external_id\")\r\n",
        "\r\n",
        "                    # Print schema after join to check the structure\r\n",
        "                    #print(\"This is the schema after joinging df to dim_org_df \")\r\n",
        "                    #df_joined.printSchema()\r\n",
        "\r\n",
        "                    # Select all columns from df (source) and only the 'organisationkey' from dim_Organisation (dim)\r\n",
        "                    # Alias the dim_Organisation's organisationkey to avoid ambiguity\r\n",
        "                    \r\n",
        "                    df_with_orgkey = df_joined.select(\r\n",
        "                        *[col(f\"source.{col_name}\") for col_name in df.columns],\r\n",
        "                        col(\"dim.organisationkey\")\r\n",
        "                    )\r\n",
        "\r\n",
        "                    # Print schema to verify the structure\r\n",
        "                    #print(\"This is the schema after only selecting the orgkey - should be df plus the orgkey \")\r\n",
        "                    #df_with_orgkey.printSchema()\r\n",
        "\r\n",
        "                    # --------------------------\r\n",
        "                    # second, get the studentkey\r\n",
        "                    # --------------------------\r\n",
        "                    \r\n",
        "                    dim_student_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Student\").select(\"student_id\", \"organisationkey\", \"studentkey\")\r\n",
        "                    # Rename the 'studentkey' column from dim_student_df to avoid ambiguity\r\n",
        "                    dim_student_df = dim_student_df.withColumnRenamed(\"studentkey\", \"dim_studentkey\")\r\n",
        "                    dim_student_df = dim_student_df.withColumnRenamed(\"student_id\", \"dim_student_id\")\r\n",
        "                    dim_student_df = dim_student_df.withColumnRenamed(\"organisationkey\", \"dim_organisationkey\")\r\n",
        "\r\n",
        "                    # Perform a left join\r\n",
        "                    df_studjoined = df_with_orgkey.alias(\"source\").join(\r\n",
        "                        dim_student_df.alias(\"dim\"),\r\n",
        "                        (trim(lower(col(\"source.student_id\"))) == trim(lower(col(\"dim.dim_student_id\")))) &\r\n",
        "                        (trim(lower(col(\"source.organisationkey\"))) == trim(lower(col(\"dim.dim_organisationkey\")))),\r\n",
        "                        \"left\"\r\n",
        "                    )\r\n",
        "\r\n",
        "                    df_studjoined = df_studjoined.drop(col(\"source.studentkey\"))\r\n",
        "                    df_studjoined = df_studjoined.drop(col(\"dim.dim_student_id\"))\r\n",
        "                    df_studjoined = df_studjoined.drop(col(\"dim.dim_organisationkey\"))\r\n",
        "\r\n",
        "                    #print(\"This is the schema after joinging df_with_orgkey to dim_student_df to get the studentkey\")\r\n",
        "                    #df_studjoined.printSchema()\r\n",
        "                  \r\n",
        "                    df = df_studjoined\r\n",
        "                    df = df.withColumnRenamed(\"dim_studentkey\", \"studentkey\")\r\n",
        "                    #print(\"This is the final schema coming out of the student block\")\r\n",
        "                    #df.printSchema()\r\n",
        "\r\n",
        "                    # debug, show 20 records\r\n",
        "                    #df.filter((col(\"studentkey\").isNotNull()) & (col(\"studentkey\") != \"\")).select(\"studentkey\").show(n=20, truncate=False)\r\n",
        "\r\n",
        "                # -------------------------------------------------------------------\r\n",
        "                # Now that any table with student_id in it has studentkey continue...\r\n",
        "                # -------------------------------------------------------------------\r\n",
        "\r\n",
        "                # Set the update columns to update everything other than organisationkey and the unique_key\r\n",
        "                update_columns = {col: f\"source.{col}\" for col in df.columns if col not in ['organisationkey', uuid_column_name]}\r\n",
        "                # print(update_columns)\r\n",
        "\r\n",
        "                if DeltaTable.isDeltaTable(spark, silver_table_path):\r\n",
        "                    delta_table = DeltaTable.forPath(spark, silver_table_path)\r\n",
        "                    try:\r\n",
        "                        delta_table.alias(\"target\").merge(\r\n",
        "                            df.alias(\"source\"),\r\n",
        "                            f\"target.{unique_key_column} = source.{unique_key_column}\"\r\n",
        "                        ).whenMatchedUpdate(set=update_columns  # Use the dictionary of columns to update\r\n",
        "                        ).whenNotMatchedInsertAll().execute()\r\n",
        "\r\n",
        "                        # debug, show 20 records\r\n",
        "                        #df.filter((col(\"studentkey\").isNotNull()) & (col(\"studentkey\") != \"\")).select(\"studentkey\").show(n=20, truncate=False)\r\n",
        "                    except Exception as e:\r\n",
        "                        print(\"Error \",delta_table_name)\r\n",
        "                        df.printSchema()\r\n",
        "                        print(e)\r\n",
        "                    \r\n",
        "                else:\r\n",
        "                    # If the table does not exist, create it by writing the current DataFrame\r\n",
        "                    # First, generate a UUID for all records in the new UUID column\r\n",
        "                    df = df.withColumn(uuid_column_name, expr(\"uuid()\"))\r\n",
        "                    if ('studentkey' not in df.columns): # because we have already added organisationkey to that\r\n",
        "                \r\n",
        "                        # Load the dim_Organisation table to get the existing mappings\r\n",
        "                        dim_org_df = spark.read.format(\"delta\").load(f\"{silver_path}/dim_Organisation\").select(\"external_id\", \"organisationkey\")\r\n",
        "                        \r\n",
        "                        #print(delta_table_name)\r\n",
        "                        #df.printSchema()\r\n",
        "\r\n",
        "                        # Perform a left join to find existing organisation keys\r\n",
        "                        df_joined = df.alias(\"source\").join(\r\n",
        "                            dim_org_df.alias(\"dim\"),\r\n",
        "                            col(\"source.school_id\") == col(\"dim.external_id\"),\r\n",
        "                            \"left\"\r\n",
        "                        )\r\n",
        "\r\n",
        "                        # Select all columns from df and only the 'organisationkey' from the dim_Organisation\r\n",
        "                        # Alias the dim_Organisation's organisationkey to avoid ambiguity\r\n",
        "                        df_with_keys = df_joined.select(\"source.*\", col(\"dim.organisationkey\").alias(\"dim_organisationkey\"))\r\n",
        "                        #df_with_keys.printSchema()\r\n",
        "                    \r\n",
        "\r\n",
        "                        # Fill in the missing keys with UUIDs\r\n",
        "                        # Ensure to use the aliased column name 'dim_organisationkey' to avoid ambiguity\r\n",
        "                        df_complete = df_with_keys.withColumn(\r\n",
        "                            \"organisationkey\",\r\n",
        "                            when(col(\"dim_organisationkey\").isNull(), expr(\"uuid()\")).otherwise(col(\"dim_organisationkey\"))\r\n",
        "                        )\r\n",
        "\r\n",
        "                        # Drop the 'dim_organisationkey' as it is no longer needed\r\n",
        "                        df = df_complete.drop(\"dim_organisationkey\")\r\n",
        "\r\n",
        "\r\n",
        "                    # debug, show 20 records\r\n",
        "                    #df.show(n=20, truncate=False)\r\n",
        "\r\n",
        "                    df.write.format(\"delta\").mode(\"overwrite\").save(silver_table_path)"
      ]
    }
  ]
}