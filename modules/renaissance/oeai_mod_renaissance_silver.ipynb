{"cells":[{"cell_type":"code","execution_count":null,"id":"dd8cd9c2-ef5d-4980-9aaa-9ea38c16e84a","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[],"source":["%run oeai_py"]},{"cell_type":"code","execution_count":null,"id":"bdbe8a5a-d426-4420-a9d7-1dc9c37fcdf2","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Create an instance of OEAI class and set the platform (\"Synapse\" or \"Fabric\")\n","oeai = OEAI(\"Fabric\")"]},{"cell_type":"code","execution_count":null,"id":"63fc36f1-79e3-43fc-a1de-c4bfed262e9d","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# CHANGE VALUES FOR YOUR KEY VAULT\n","keyvault = \"INSERT_YOUR_KEYVAULT_NAME\" # fully qualified for Fabric \n","keyvault_linked_service = \"INSERT_YOUR_KEYVAULT_LINKED_SERVICE_NAME\" # linked service name for Synapse\n","\n","# Synapse OEA environment path & secrets\n","bronze_path = oeai.get_secret(spark, \"renaissance-bronze\", keyvault_linked_service, keyvault)\n","silver_path = oeai.get_secret(spark, \"renaissance-silver\", keyvault_linked_service, keyvault)\n","school_ids_secret = oeai.get_secret(spark, \"renaissance-school-ids\", keyvault_linked_service, keyvault)\n","subdirectories = school_ids_secret.split(\",\")"]},{"cell_type":"code","execution_count":null,"id":"9f3549e2-1ecd-457a-8ad0-f17ca63fbab5","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["school_ids_secret = oeai.get_secret(spark, \"renaissance-school-ids\", keyvault_linked_service, keyvault)\n","subdirectories = school_ids_secret.split(\",\")\n","# print(subdirectories)"]},{"cell_type":"code","execution_count":null,"id":"9f560506-341b-404c-9e16-6ba88d7e73e5","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["from pyspark.sql import SparkSession\n","import zipfile\n","from io import BytesIO\n","import pandas as pd\n","from urllib.parse import quote\n","\n","base_path = bronze_path\n","\n","# Function to extract AR_UK.csv from a zip file\n","def extract_csv_from_zip(zip_data):\n","    with zipfile.ZipFile(BytesIO(zip_data), 'r') as zip_ref:\n","        for file in zip_ref.namelist():\n","            if file.endswith(\"AR_UK.csv\"):\n","                with zip_ref.open(file) as f:\n","                    return pd.read_csv(f)\n","\n","# List to hold DataFrames\n","df_list = []\n","\n","# Loop through zip files in ADLS, extract AR_UK.csv, and combine them into a DataFrame\n","for subdir in subdirectories:\n","    zip_file_path = f\"{base_path}{subdir}\"\n","    print(f\"Checking file: {zip_file_path}\")  # Debug statement\n","    try:\n","        binary_files_df = spark.read.format(\"binaryFile\").load(zip_file_path)\n","        zip_data = binary_files_df.select(\"content\").collect()[0][0]\n","        pdf = extract_csv_from_zip(zip_data)\n","        if pdf is not None:\n","            df = spark.createDataFrame(pdf)\n","            df_list.append(df)\n","    except Exception as e:\n","        print(f\"Failed to process {zip_file_path}: {e}\")\n","\n","# Combine all DataFrames if there are any\n","if df_list:\n","    combined_df = df_list[0]\n","    for df in df_list[1:]:\n","        combined_df = combined_df.union(df)\n","    # Show the combined DataFrame\n","    combined_df.show()\n","    # Save the combined DataFrame as a Delta table\n","    delta_path = silver_path + \"fact_AcceleratedReader\"\n","    combined_df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n","else:\n","    print(\"No files were processed.\")\n"]}],"metadata":{"dependencies":{},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
